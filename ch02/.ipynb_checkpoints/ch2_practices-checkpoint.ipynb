{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scott Ming 2017-06-10 \n",
      "\n",
      "CPython 3.6.0\n",
      "IPython 6.0.0\n",
      "\n",
      "numpy 1.12.1\n",
      "sklearn 0.18.1\n",
      "\n",
      "compiler   : GCC 4.9.2\n",
      "system     : Linux\n",
      "release    : 3.16.0-4-amd64\n",
      "machine    : x86_64\n",
      "processor  : \n",
      "CPU cores  : 2\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -a 'Scott Ming' -v -m -d -p numpy,sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 留出法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "iris = fetch_mldata('iris')\n",
    "X, y = iris['data'], iris['target']\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(np.unique(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "「留出法」(hold-out) 直接将数据集 $D$ 划分成两个互斥的组合，比较常见的训练集和测试集有 8:2，7:3 的比例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data[train_indices], data[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 train + 30 test\n"
     ]
    }
   ],
   "source": [
    "dataset = np.c_[X, y]\n",
    "train_set, test_set = split_train_test(dataset, 0.2)\n",
    "print(len(train_set), 'train +', len(test_set), 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ageron/handson-ml](https://github.com/ageron/handson-ml) 这书 p50 提到这种方法会还不够完美，会\n",
    "> But both these solutions will break next time you fetch an updated dataset    \n",
    "> 打乱更新之后的数据集\n",
    "\n",
    "然后提到 sklearn 实作的函数比较完美，但更新之后的数据一样会打乱吧，这点我不太明白？    \n",
    "我目前感觉这个函数比较好用的地方在于第一个参数能接收的数据类型比较多，多种数据结构切换的时候比较方便。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Shuffle dataset \n",
    "train_set, test_set = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "# Shuffle X, y\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 交叉验证法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Holdout validation is actually a specific example of a larger class of validation techniques called k-fold cross-validation. K-fold cross-validation works by:\n",
    "\n",
    "* splitting the full dataset into k equal length partitions,\n",
    "    + selecting k-1 partitions as the training set and\n",
    "    + selecting the remaining partition as the test set\n",
    "* training the model on the training set,\n",
    "* using the trained model to predict labels on the test set,\n",
    "* computing an error metric (e.g. simple accuracy) and setting aside the value for later,\n",
    "* repeating all of the above steps k-1 times, until each partition has been used as the test set for an iteration,\n",
    "* calculating the mean of the k error values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gpa</th>\n",
       "      <th>gre</th>\n",
       "      <th>actual_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>631</td>\n",
       "      <td>3.567503</td>\n",
       "      <td>570.997409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>592</td>\n",
       "      <td>3.674243</td>\n",
       "      <td>637.922531</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>599</td>\n",
       "      <td>3.208536</td>\n",
       "      <td>737.168076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>291</td>\n",
       "      <td>3.183651</td>\n",
       "      <td>675.172488</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>72</td>\n",
       "      <td>3.116568</td>\n",
       "      <td>650.321216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       gpa         gre  actual_label\n",
       "0    631  3.567503  570.997409             1\n",
       "1    592  3.674243  637.922531             1\n",
       "2    599  3.208536  737.168076             1\n",
       "3    291  3.183651  675.172488             0\n",
       "4     72  3.116568  650.321216             0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "admissions = pd.read_csv(\"admissions.csv\")\n",
    "admissions[\"actual_label\"] = admissions[\"admit\"]\n",
    "admissions = admissions.drop(\"admit\", axis=1)\n",
    "\n",
    "np.random.seed(42)\n",
    "shuffled_index = np.random.permutation(admissions.index)\n",
    "shuffled_admissions = admissions.loc[shuffled_index]\n",
    "admissions = shuffled_admissions.reset_index()\n",
    "\n",
    "admissions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Partitioning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index       gpa         gre  actual_label  fold\n",
      "0    631  3.567503  570.997409             1     1\n",
      "1    592  3.674243  637.922531             1     1\n",
      "2    599  3.208536  737.168076             1     1\n",
      "3    291  3.183651  675.172488             0     1\n",
      "4     72  3.116568  650.321216             0     1\n",
      "\n",
      "     index       gpa         gre  actual_label  fold\n",
      "639     71  3.691417  496.273937             0     5\n",
      "640    106  3.465695  578.830098             0     5\n",
      "641    270  3.040767  749.832685             0     5\n",
      "642    435  3.086840  720.697055             1     5\n",
      "643    102  3.405693  673.922493             0     5\n"
     ]
    }
   ],
   "source": [
    "# 把数据集化成 5 份\n",
    "kfold_indexes = [\n",
    "    (0, 128),\n",
    "    (129, 257),\n",
    "    (258, 386),\n",
    "    (387, 514),\n",
    "    (515, 644),\n",
    "]\n",
    "\n",
    "admissions['fold'] = np.nan\n",
    "for fold_name, (start, end) in enumerate(kfold_indexes, 1):\n",
    "    determine = admissions.index.isin(range(start, end + 1))\n",
    "    admissions['fold'] = np.where(determine, fold_name, admissions['fold'])\n",
    "\n",
    "admissions['fold'] = admissions.fold.astype('int')\n",
    "print(admissions.head(), end='\\n\\n')\n",
    "print(admissions.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. First Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.697674418605\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "train_set = admissions[admissions.fold != 1]\n",
    "test_set = admissions[admissions.fold == 1]\n",
    "X_train, y_train = train_set[['gpa']].values, train_set.actual_label.values\n",
    "X_test, y_test = test_set[['gpa']].values, test_set.actual_label.values\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "iteration_one_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(iteration_one_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Function for Training Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.641194282946\n"
     ]
    }
   ],
   "source": [
    "def train_and_test(data, fold_names):\n",
    "    accuracies = []\n",
    "    for fold_name in fold_names:\n",
    "        train_set = admissions[admissions.fold != fold_name]\n",
    "        test_set = admissions[admissions.fold == fold_name]\n",
    "        X_train, y_train = train_set[['gpa']].values, train_set.actual_label.values\n",
    "        X_test, y_test = test_set[['gpa']].values, test_set.actual_label.values\n",
    "        # Training data\n",
    "        lr = LogisticRegression()\n",
    "        lr.fit(X_train, y_train)\n",
    "        y_pred = lr.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    return accuracies\n",
    "\n",
    "fold_ids = [1,2,3,4,5]\n",
    "accuracies = train_and_test(admissions, fold_ids)\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.68217054  0.66666667  0.62015504  0.62015504  0.640625  ]\n",
      "0.645954457364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X = admissions[['gpa']]\n",
    "y = admissions['actual_label']\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=8)\n",
    "lr = LogisticRegression()\n",
    "\n",
    "accuracies = cross_val_score(lr, X, y, scoring='accuracy', cv=kf)\n",
    "average_accuracy = sum(accuracies) / len(accuracies)\n",
    "\n",
    "print(accuracies)\n",
    "print(average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上是 dataquest.io 关于交叉验证的练习"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Practices"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 试述真正例率（TPR）、假正例率（FPR）与查准率（P）、查全率（R）之间的联系\n",
    "\n",
    "**Confusion matrix:**\n",
    "\n",
    "名称|含义|预测方向\n",
    "----|----|--------\n",
    "True Negative|正确预测成负例|0 -> 0\n",
    "True Positive|正确预测成正例|1 -> 1\n",
    "False Positive|错误预测成正例(即负例预测成正例)|0 -> 1\n",
    "False Negative|错误预测成负例(即正例预测成负例)|1 -> 0\n",
    "\n",
    "![image.png](http://www.dataschool.io/content/images/2015/01/confusion_matrix2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$TPR = \\frac{TP}{actual\\ yes} = \\frac{TP}{FN+TP} = \\frac{100}{105}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$FPR = \\frac{FP}{actual\\ no} = \\frac{FP}{TN+FP} = \\frac{50}{60}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P = \\frac{TP}{predicted\\ yes} = \\frac{TP}{TP+FP} = \\frac{100}{110}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$R = \\frac{TP}{actual\\ yes} = \\frac{TP}{TP+FN} = \\frac{100}{105}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从上面表格可以看出\n",
    "\n",
    "TPR 和 R 相等，而和 P 没有数值关系。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Intro to Binary Classification: Machine Learning with Python - Tutorial](https://www.dataquest.io/m/22/introduction-to-evaluating-binary-classifiers/3/binary-classification-outcomes)\n",
    "* [Simple guide to confusion matrix terminology](http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 个关于 confusion matrix 的工具:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[79  3]\n",
      " [40  7]]\n",
      "Test Accuracy: 0.666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X = admissions[['gpa']].values\n",
    "y = admissions['actual_label'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Confusion Matrix:\\n', cm)\n",
    "print('Test Accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAAC4CAYAAAClza13AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nL7ULjpfaBcdL7YLjpXbB+X/MoOBvguQdKAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fcd18717ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "plot_confusion_matrix(cm);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TN 挺高，但 TP 很差劲"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted    0   1  __all__\n",
      "Actual                     \n",
      "0           79   3       82\n",
      "1           40   7       47\n",
      "__all__    119  10      129\n",
      "\n",
      "Confusion Matrix Stats:\n",
      "population: 129\n",
      "P: 47\n",
      "N: 82\n",
      "PositiveTest: 10\n",
      "NegativeTest: 119\n",
      "TP: 7\n",
      "TN: 79\n",
      "FP: 3\n",
      "FN: 40\n",
      "TPR: 0.148936170213\n",
      "TNR: 0.963414634146\n",
      "PPV: 0.7\n",
      "NPV: 0.663865546218\n",
      "FPR: 0.0365853658537\n",
      "FDR: 0.3\n",
      "FNR: 0.851063829787\n",
      "ACC: 0.666666666667\n",
      "F1_score: 0.245614035088\n",
      "MCC: 0.202189482408\n",
      "informedness: 0.112350804359\n",
      "markedness: 0.363865546218\n",
      "prevalence: 0.364341085271\n",
      "LRP: 4.07092198582\n",
      "LRN: 0.883382709399\n",
      "DOR: 4.60833333333\n",
      "FOR: 0.336134453782\n"
     ]
    }
   ],
   "source": [
    "from pandas_ml import ConfusionMatrix\n",
    "\n",
    "cm = ConfusionMatrix(y_test, y_pred)\n",
    "print(cm, end='\\n\\n')\n",
    "print('Confusion Matrix Stats:')\n",
    "cm.print_stats()"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
